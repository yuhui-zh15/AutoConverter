{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from textwrap import dedent\n",
    "from tqdm import tqdm, trange\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "\n",
    "client = OpenAI(timeout=20)\n",
    "\n",
    "\n",
    "def base64_to_image(base64_str):\n",
    "    image_data = base64.b64decode(base64_str)\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    return image\n",
    "\n",
    "\n",
    "class Judgement(BaseModel):\n",
    "    reasoning: str\n",
    "    correctness: int\n",
    "\n",
    "\n",
    "class Question(BaseModel):\n",
    "    reasoning: str\n",
    "    distractors: list[str]\n",
    "\n",
    "\n",
    "client = OpenAI(timeout=20)\n",
    "\n",
    "\n",
    "def judge_multichoice_correctness_with_image(\n",
    "    image_base64: str, question: str, choices: list, correct_choice: str\n",
    ") -> str:\n",
    "    # system_prompt = f\"\"\"\n",
    "    # Your task is to evaluate a multiple-choice question (with accompanying image) to determine if any incorrect choices (distractors) could also be considered correct answers.\n",
    "\n",
    "    # CRITICAL: The marked correct answer MUST always be treated as valid and correct, regardless of your own assessment. Never question or evaluate the correct answer - your task is to accept it as an absolute truth and evaluate only whether other choices could also be correct.\n",
    "\n",
    "    # Score the question's correctness using this scale:\n",
    "    # 5 - Perfect: All other choices are clearly incorrect\n",
    "    # 4 - Good: Other choices are mostly wrong but have minor elements of correctness\n",
    "    # 3 - Fair: At least one other choice could be partially correct\n",
    "    # 2 - Poor: At least one other choice could be equally correct\n",
    "    # 1 - Invalid: Multiple choices are equally valid as the correct answer\n",
    "\n",
    "    # Provide:\n",
    "    # 1. Score (1-5)\n",
    "    # 2. Brief explanation focusing specifically on any problematic distractor choices\n",
    "    # 3. Suggested improvements for the problematic distractors (if applicable)\n",
    "\n",
    "    # Remember: Never analyze whether the marked correct answer is right or wrong - it is ALWAYS correct by definition. Focus exclusively on whether other choices could also be valid answers.\n",
    "    # \"\"\"\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    Your task is to evaluate a multiple-choice question (with accompanying image) to determine if any incorrect choices (distractors) could also be considered correct answers.\n",
    "\n",
    "    CRITICAL: The marked correct answer MUST always be treated as valid and correct, regardless of your own assessment. Never question or evaluate the correct answer - your task is to accept it as an absolute truth and evaluate only whether other choices could also be correct.\n",
    "\n",
    "    Score the question's correctness using this scale:\n",
    "    5 - Perfect: All other choices are clearly incorrect\n",
    "    4 - Good: Other choices are mostly wrong but have minor elements of correctness\n",
    "    3 - Fair: At least one other choice could be partially correct\n",
    "    2 - Poor: At least one other choice could be equally correct\n",
    "    1 - Invalid: Multiple choices are equally valid as the correct answer\n",
    "\n",
    "    Provide:\n",
    "    1. Score (1-5)\n",
    "    2. Brief explanation focusing specifically on any problematic distractor choices\n",
    "\n",
    "    Remember: Never analyze whether the marked correct answer is right or wrong - it is ALWAYS correct by definition. Focus exclusively on whether other choices could also be valid answers.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Question: {question}\n",
    "    Choices: {choices}\n",
    "    Correct Answer: {correct_choice}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": dedent(system_prompt),\n",
    "            },  # \"You are a helpful assistant.\"\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": dedent(prompt)},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"},\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        response_format=Judgement,\n",
    "        temperature=0,  # Set to 0 for deterministic responses\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.parsed.dict()\n",
    "    return answer\n",
    "\n",
    "\n",
    "def improve_multichoice_correctness_with_image(\n",
    "    image_base64: str,\n",
    "    question: str,\n",
    "    choices: list,\n",
    "    correct_choice: str,\n",
    "    issue: str,\n",
    "    improvement: str,\n",
    ") -> str:\n",
    "    system_prompt = \"\"\"\n",
    "    You are an expert in educational assessment design specializing in multiple-choice question improvement. Your task is to enhance question effectiveness by revising problematic distractors (incorrect answer choices) while maintaining the existing correct answer.\n",
    "\n",
    "    Input Required:\n",
    "    1. The complete question\n",
    "    2. The current correct answer\n",
    "    3. Any associated images/materials\n",
    "    4. Specific feedback about problematic distractors\n",
    "    5. Suggested improvements (if provided)\n",
    "\n",
    "    Analysis Steps:\n",
    "    1. Review the question content and learning objective\n",
    "    2. Analyze the designated correct answer\n",
    "    3. Examine the feedback regarding problematic distractors\n",
    "    4. Evaluate any provided suggestions for improvement:\n",
    "    - Assess if suggestions fully address the identified issues\n",
    "    - Determine if suggestions align with best practices\n",
    "    - Identify any gaps or weaknesses in the suggestions\n",
    "    5. Develop exactly 3 improved distractors that:\n",
    "    - Are plausible but clearly incorrect\n",
    "    - Address the identified issues\n",
    "    - Align with common student misconceptions\n",
    "    - Maintain consistent format and length with other options\n",
    "    - Go beyond provided suggestions when necessary for better quality\n",
    "\n",
    "    Guidelines:\n",
    "    1. Treat the marked correct answer as fixed and unchangeable\n",
    "    2. Only modify distractors specifically identified as problematic\n",
    "    3. Preserve any well-functioning distractors\n",
    "    4. Maintain the original difficulty level of the question\n",
    "    5. Use your expertise to improve upon or deviate from provided suggestions if they:\n",
    "    - Are too vague or incomplete\n",
    "    - Don't fully address the identified issues\n",
    "    - Could be enhanced for better assessment quality\n",
    "    - Miss important misconceptions or learning opportunities\n",
    "\n",
    "    Output:\n",
    "    1. Brief analysis of the distractor issues and improvement approach\n",
    "    2. Three improved distractors\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Question: {question}\n",
    "    Choices: {choices}\n",
    "    Correct Answer: {correct_choice}\n",
    "    Identified Issues: {issue}\n",
    "    Suggested Improvements: {improvement}\n",
    "    \"\"\"\n",
    "\n",
    "    # print(prompt)\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": dedent(system_prompt),\n",
    "            },  # \"You are a helpful assistant.\"\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": dedent(prompt)},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"},\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "        response_format=Question,\n",
    "        temperature=0,  # Set to 0 for deterministic responses\n",
    "    )\n",
    "\n",
    "    distractors = response.choices[0].message.parsed.dict()\n",
    "    return distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = [json.loads(line) for line in open(\"/pasteur2/u/yuhuiz/CVPR/AutoConverter/data/MMMU-500-v2-naive.jsonl\")]\n",
    "data = pd.read_csv(\"/pasteur2/u/yuhuiz/CVPR/AutoConverter/data/MMMU-500-v2.tsv\", sep=\"\\t\").to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "# import random\n",
    "# random.seed(134)\n",
    "# data = random.sample(data, 300)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': \"The correct answer is marked as '5t^2 [u(t) - u(t - 2)] + 20[u(t - 2) - u(t - 5)] + 15(t - 7)[u(t - 5) - u(t - 7)]'. This matches the behavior of the signal in the image: a quadratic rise from 0 to 2, a constant value from 2 to 5, and a linear decrease from 5 to 7. The other choices have incorrect coefficients or intervals, such as '4t^2' instead of '5t^2', or incorrect step function intervals, making them clearly incorrect.\",\n",
       " 'correctness': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_item(item):\n",
    "    return judge_multichoice_correctness_with_image(\n",
    "        item[\"image\"],\n",
    "        item[\"question\"],\n",
    "        [item[\"A\"], item[\"B\"], item[\"C\"], item[\"D\"]],\n",
    "        item[item[\"answer\"]]\n",
    "    )\n",
    "\n",
    "process_item(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:55<00:00,  8.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# predictions = []\n",
    "# for item in tqdm(annotations):\n",
    "#     prediction = judge_multichoice_correctness_with_image(item[\"image\"], item[\"question\"], [item[\"A\"], item[\"B\"], item[\"C\"], item[\"D\"]], item[item[\"answer\"]])\n",
    "#     predictions.append(prediction)\n",
    "\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def parallel_judge(data):\n",
    "    with ProcessPoolExecutor(max_workers=32) as executor:\n",
    "        results = list(tqdm(executor.map(process_item, data), total=len(data)))\n",
    "    return results\n",
    "\n",
    "predictions = parallel_judge(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.58\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean([p[\"correctness\"] for p in predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.594\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "json.dump(predictions, open(\"/pasteur2/u/yuhuiz/CVPR/AutoConverter/data/MMMU-500-v2-naive_correctness.jsonl\", \"w\"))\n",
    "print(np.mean([p[\"correctness\"] for p in predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.511278195488722\n",
      "4.6066666666666665\n",
      "4.503333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "predictions = json.load(open(\"/pasteur2/u/yuhuiz/CVPR/AutoConverter/data/MMMU_DEV_VAL_4choices_original_correctness.jsonl\"))\n",
    "print(np.mean([p[\"correctness\"] for p in predictions]))\n",
    "\n",
    "predictions = json.load(open(\"/pasteur2/u/yuhuiz/CVPR/AutoConverter/data/MMMU_DEV_VAL_4choices_naive_correctness.jsonl\"))\n",
    "print(np.mean([p[\"correctness\"] for p in predictions]))\n",
    "\n",
    "predictions = json.load(open(\"/pasteur2/u/yuhuiz/CVPR/AutoConverter/data/MMMU-500-MC-v2-validated_correctness.jsonl\"))\n",
    "print(np.mean([p[\"correctness\"] for p in predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': \"The correct answer specifically addresses W.E.B. Du Bois's concept of 'double consciousness,' which is about the African American experience. The second choice, while related to viewing oneself through others' opinions, is more general and not specific to Du Bois's concept. The third and fourth choices are about internal conflicts and integration into new cultures, which are not directly related to Du Bois's idea of double consciousness.\",\n",
       " 'correctness': 5,\n",
       " 'improvement': 'No improvements needed as the distractors are clearly incorrect.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlmeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
